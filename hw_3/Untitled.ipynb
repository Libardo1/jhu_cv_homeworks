{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv, cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import skimage\n",
    "import skimage.io as io\n",
    "from skimage.transform import rescale\n",
    "from skimage.color import rgb2gray\n",
    "from skimage import img_as_ubyte\n",
    "\n",
    "sift = cv2.SIFT()\n",
    "\n",
    "biggest_axis_threshold = 512\n",
    "\n",
    "def image_rescale_loader(image_path):\n",
    "    \n",
    "    image = io.imread(image_path)\n",
    "    \n",
    "    rows_number = image.shape[0]\n",
    "    cols_number = image.shape[1]\n",
    "\n",
    "    biggest_axis = rows_number if rows_number > cols_number else cols_number\n",
    "\n",
    "    biggest_axis = rows_number if rows_number > cols_number else cols_number\n",
    "\n",
    "    if biggest_axis > biggest_axis_threshold:\n",
    "\n",
    "        ratio = biggest_axis_threshold / float(biggest_axis)\n",
    "\n",
    "        image = rescale(image, ratio)\n",
    "    \n",
    "    return img_as_ubyte(rgb2gray(image))\n",
    "\n",
    "def compute_images_sift_features(images):\n",
    "    \n",
    "    return map(lambda image: sift.detectAndCompute(image, None)[1], images)\n",
    "\n",
    "def train_classifier(images, number_of_clusters=1000):\n",
    "\n",
    "    img_number = len(images)\n",
    "\n",
    "    # Detect and compute Sift descriptor features in each image\n",
    "    features = compute_images_sift_features(images)\n",
    "\n",
    "    # Get the index of where for each feature the respective training image label\n",
    "    # is provided. This is done to compute histogram descriptors of each training sample\n",
    "    training_set_indexes = np.asarray([])\n",
    "\n",
    "    for ind, feature in enumerate(features):\n",
    "\n",
    "        amount_of_elements = feature.shape[0]\n",
    "        indexes_to_append = np.repeat(ind, amount_of_elements)\n",
    "        training_set_indexes = np.append(training_set_indexes, indexes_to_append)\n",
    "\n",
    "    # Put all the descriptors in one array to find clusters (bag of words)\n",
    "    training_set = np.vstack(features)\n",
    "\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "\n",
    "    _, labels, centers = cv2.kmeans(training_set, number_of_clusters, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "\n",
    "    # Make labels array as one dimensional list\n",
    "    labels = np.concatenate(labels)\n",
    "\n",
    "    image_descriptors = np.zeros((img_number, number_of_clusters))\n",
    "\n",
    "    for current_img_number in range(img_number):\n",
    "\n",
    "        # Get the words of the current image\n",
    "        current_img_words = labels[training_set_indexes == current_img_number]\n",
    "\n",
    "        current_img_words_number = len(current_img_words)\n",
    "\n",
    "        current_histogram = np.bincount(current_img_words, minlength=number_of_clusters).astype(np.float32)\n",
    "\n",
    "        # Normalize histogram of the current word\n",
    "        current_histogram = current_histogram / current_img_words_number\n",
    "\n",
    "        image_descriptors[current_img_number, :] = current_histogram\n",
    "\n",
    "    return centers, image_descriptors\n",
    "\n",
    "def get_images_filenames(images_folder, image_categories_folders,\n",
    "                         amount_of_images_to_take=8, fetch_from_beginnig=True):\n",
    "\n",
    "    images_filenames_list = []\n",
    "    \n",
    "    number_of_categories = len(image_categories_folders)\n",
    "    \n",
    "    labels = np.repeat(np.arange(number_of_categories), amount_of_images_to_take)\n",
    "    \n",
    "    for current_category_folder in image_categories_folders:\n",
    "\n",
    "        # Get the full path to current category folder\n",
    "        current_category_folder_full_path = os.path.join(images_folder, current_category_folder)\n",
    "\n",
    "        # Get all the files in current category directory folder\n",
    "        current_category_filenames = os.listdir(current_category_folder_full_path)\n",
    "\n",
    "        # Sort all the filename in lexigraphical order. This is to get the filenames\n",
    "        # sorted like 01.jpg, 02.jpg, 03.jpg and so on.\n",
    "        current_category_filenames.sort()\n",
    "\n",
    "        # Take the images from the beginning or from the end.\n",
    "        if fetch_from_beginnig:\n",
    "            images_filenames_to_add = current_category_filenames[:amount_of_images_to_take]\n",
    "        else:\n",
    "            images_filenames_to_add = current_category_filenames[-amount_of_images_to_take:]\n",
    "\n",
    "        images_filenames_to_add = map(lambda x: os.path.join(current_category_folder_full_path, x), images_filenames_to_add)\n",
    "\n",
    "        images_filenames_list.extend(images_filenames_to_add)\n",
    "\n",
    "    return images_filenames_list, labels\n",
    "\n",
    "def closest_vector(vector_to_check, vectors_to_compare_to):\n",
    "    \n",
    "    return np.argmin(((vector_to_check - vectors_to_compare_to)**2).sum(axis=1))\n",
    "\n",
    "def closest_vector_batch(vectors_to_check, vectors_to_compare_to):\n",
    "    \n",
    "    return np.asarray(map(lambda x: closest_vector(x, vectors_to_compare_to), vectors_to_check))\n",
    "\n",
    "def compute_bag_of_words_repr(feature_vect, clusters):\n",
    "    \n",
    "    number_of_clusters = clusters.shape[0]\n",
    "    \n",
    "    img_words_number = feature_vect.shape[0]\n",
    "    \n",
    "    bag_of_words_count = closest_vector_batch(feature_vect, clusters)\n",
    "    \n",
    "    bag_of_words_count = np.bincount(bag_of_words_count, minlength=number_of_clusters).astype(np.float32)\n",
    "    \n",
    "    bag_of_words_frequency = bag_of_words_count / img_words_number\n",
    "    \n",
    "    return bag_of_words_frequency\n",
    "\n",
    "def compute_bag_of_words_repr_batch(feature_vectors, clusters):\n",
    "    \n",
    "    result = map(lambda x: compute_bag_of_words_repr(x, clusters), feature_vectors)\n",
    "    \n",
    "    return np.vstack(result)\n",
    "\n",
    "def images_to_bag_of_words_histogram(images, clusters):\n",
    "    \n",
    "    images_features = compute_images_sift_features(images)\n",
    "    images_histograms = compute_bag_of_words_repr_batch(images_features, clusters)\n",
    "    \n",
    "    return images_histograms\n",
    "\n",
    "def nearest_neighbour_classifier(train_features, train_features_labels, test_features):\n",
    "    \n",
    "    res = closest_vector_batch(test_features, train_features)\n",
    "    \n",
    "    return train_features_labels[res]\n",
    "\n",
    "def get_classification_accuracy(ground_truth_labels, check_labels):\n",
    "    \n",
    "    return (ground_truth_labels == check_labels).sum() / float(check_labels.shape[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['images/buildings/01.jpg', 'images/buildings/02.jpg', 'images/buildings/03.jpg', 'images/buildings/04.jpg', 'images/buildings/05.jpg', 'images/buildings/06.jpg', 'images/buildings/07.jpg', 'images/buildings/08.jpg', 'images/buildings/09.jpg', 'images/cars/01.jpg', 'images/cars/02.jpg', 'images/cars/03.jpg', 'images/cars/04.jpg', 'images/cars/05.jpg', 'images/cars/06.jpg', 'images/cars/07.jpg', 'images/cars/08.jpg', 'images/cars/09.jpg', 'images/faces/01.jpg', 'images/faces/02.jpg', 'images/faces/03.jpg', 'images/faces/04.jpg', 'images/faces/05.jpg', 'images/faces/06.jpg', 'images/faces/07.jpg', 'images/faces/08.jpg', 'images/faces/09.jpg', 'images/food/01.jpg', 'images/food/02.jpg', 'images/food/03.jpg', 'images/food/04.jpg', 'images/food/05.jpg', 'images/food/06.jpg', 'images/food/07.jpg', 'images/food/08.jpg', 'images/food/09.jpg', 'images/people/01.jpg', 'images/people/02.jpg', 'images/people/03.jpg', 'images/people/04.jpg', 'images/people/05.jpg', 'images/people/06.jpg', 'images/people/07.jpg', 'images/people/08.jpg', 'images/people/09.jpg', 'images/trees/01.jpg', 'images/trees/02.jpg', 'images/trees/03.jpg', 'images/trees/04.jpg', 'images/trees/05.jpg', 'images/trees/06.jpg', 'images/trees/07.jpg', 'images/trees/08.jpg', 'images/trees/09.jpg']\n",
      "['images/buildings/10.jpg', 'images/buildings/11.jpg', 'images/cars/10.jpg', 'images/cars/11.jpg', 'images/faces/10.jpg', 'images/faces/11.jpg', 'images/food/10.jpg', 'images/food/11.jpg', 'images/people/10.jpg', 'images/people/11.jpg', 'images/trees/10.jpg', 'images/trees/11.jpg']\n"
     ]
    }
   ],
   "source": [
    "images_folder = 'images'\n",
    "image_categories_folders = ['buildings', 'cars', 'faces', 'food', 'people', 'trees']\n",
    "number_of_images = 11\n",
    "number_of_train_images = 9\n",
    "number_of_test_images = number_of_images - number_of_train_images\n",
    "\n",
    "train_images_filenames, train_images_class_labels = get_images_filenames(images_folder, image_categories_folders,\n",
    "                                                                         number_of_train_images)\n",
    "\n",
    "test_images_filenames, test_images_class_labels = get_images_filenames(images_folder, image_categories_folders,\n",
    "                                                                        number_of_test_images, fetch_from_beginnig=False)\n",
    "\n",
    "print train_images_filenames\n",
    "print test_images_filenames\n",
    "\n",
    "train_images = io.ImageCollection(train_images_filenames, load_func=image_rescale_loader)\n",
    "test_images = io.ImageCollection(test_images_filenames, load_func=image_rescale_loader)\n",
    "\n",
    "cluster_centers, train_images_histograms = train_classifier(train_images, number_of_clusters=100)\n",
    "\n",
    "test_images_histograms = images_to_bag_of_words_histogram(test_images, cluster_centers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.666666666667\n",
      "[0 0 1 1 2 2 3 3 4 4 5 5]\n",
      "[0 1 3 3 3 2 3 3 4 4 5 5]\n"
     ]
    }
   ],
   "source": [
    "clas = nearest_neighbour_classifier(train_images_histograms, train_images_class_labels, test_images_histograms)\n",
    "real = test_images_class_labels\n",
    "\n",
    "print get_classification_accuracy(real, clas)\n",
    "\n",
    "print real\n",
    "print clas\n",
    "\n",
    "#print test_images_class_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import skimage.io as io\n",
    "from skimage.util import pad, view_as_windows\n",
    "import numpy as np\n",
    "from scipy.ndimage.filters import generic_filter\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def normalize_matrix(matrix):\n",
    "    \n",
    "    matrix = matrix - matrix.mean()\n",
    "    \n",
    "    # Stand. deviation\n",
    "    matrix_std = np.sqrt((matrix**2).sum())\n",
    "\n",
    "    matrix = matrix / matrix_std\n",
    "    \n",
    "    return matrix\n",
    "\n",
    "window_size = 15\n",
    "\n",
    "img_l = io.imread('HW3_images/scene_l.bmp')\n",
    "img_r = io.imread('HW3_images/scene_r.bmp')\n",
    "\n",
    "# Integer division\n",
    "pad_width = window_size / 2\n",
    "window_shape = (window_size, window_size)\n",
    "\n",
    "img_l_padded = pad(img_l, pad_width=pad_width, mode='symmetric')\n",
    "img_r_padded = pad(img_r, pad_width=pad_width, mode='symmetric')\n",
    "\n",
    "img_l_view = view_as_windows(img_l_padded, window_shape=window_shape, step=1)\n",
    "img_r_view = view_as_windows(img_r_padded, window_shape=window_shape, step=1)\n",
    "\n",
    "img_height, img_width = img_l.shape\n",
    "\n",
    "result = np.zeros(img_l.shape)\n",
    "\n",
    "for row in xrange(img_height):\n",
    "    for col in xrange(img_width):\n",
    "        \n",
    "        first_patch = img_l_view[row, col]\n",
    "        \n",
    "        first_patch_norm = normalize_matrix(first_patch)\n",
    "        \n",
    "        current_scanline = img_r_view[row, :]\n",
    "        scores = np.zeros(img_width)\n",
    "        \n",
    "        for pixel in xrange(img_width):\n",
    "            \n",
    "            second_patch = current_scanline[pixel]\n",
    "            \n",
    "            second_patch_norm = normalize_matrix(second_patch)\n",
    "            \n",
    "            scores[pixel] = (first_patch_norm * second_patch_norm).sum()\n",
    "            \n",
    "        best_match = np.argmax(scores)\n",
    "        \n",
    "        result[row, col] = best_match\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dan/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:16: RuntimeWarning: divide by zero encountered in divide\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# pixels\n",
    "f = 400\n",
    "\n",
    "#mm\n",
    "b = 100\n",
    "\n",
    "horiz_span = np.arange(img_width)\n",
    "u_l = np.tile(horiz_span, (img_height, 1))\n",
    "\n",
    "\n",
    "vert_span = np.arange(img_height).reshape((-1, 1))\n",
    "v_l = np.tile(vert_span, (1, img_width))\n",
    "\n",
    "z = f*b / (u_l - result)\n",
    "z[z > 10000] = 0\n",
    "\n",
    "x = b* ((u_l + result) / 2*(u_l - result))\n",
    "y = b* ((v_l + v_l) / 2*(u_l - result))\n",
    "\n",
    "\n",
    "# io.imshow(z, cmap=plt.get_cmap('gray'))\n",
    "# io.show()\n",
    "\n",
    "strings_to_write = []\n",
    "\n",
    "for row in xrange(img_height):\n",
    "    for col in xrange(img_width):\n",
    "        \n",
    "        data = [str(x[row, col]), str(y[row, col]), str(z[row, col])]\n",
    "        new_string = \" \".join(data)\n",
    "        strings_to_write.append(new_string)\n",
    "        \n",
    "file_contents = '\\n'.join(strings_to_write)\n",
    "\n",
    "with open('point_cloud.txt', 'w') as the_file:\n",
    "    the_file.write(file_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 20 30\n",
      "10.9\n"
     ]
    }
   ],
   "source": [
    "one = '10'\n",
    "\n",
    "two = '20'\n",
    "\n",
    "three = '30'\n",
    "\n",
    "print \" \".join([one, two, three])\n",
    "\n",
    "print str(10.9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
